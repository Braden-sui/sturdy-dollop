services:
  ollama:
    image: ollama/ollama
    volumes:
      - ./models:/root/.ollama/models
      - .:/app # To access Modelfile from project root
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true # Ensures container stays running
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  api:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - VLLM_URL=http://ollama:11434 # Updated to point to the ollama server
      - VLLM_MODEL_NAME=magistral-small:latest # Model name for Ollama
      - MEM0_API_KEY=${MEM0_API_KEY}
      - MEM0_ORG_ID=${MEM0_ORG_ID}
      - MEM0_PROJECT_ID=${MEM0_PROJECT_ID}
      - BRAVE_API_KEY=${BRAVE_API_KEY}
      - NEWS_API_KEY=${NEWS_API_KEY}
      - REDIS_URL=redis://redis:6379

      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - ollama # Updated dependency
      - redis

    volumes:
      - ./api:/app/api
      - ./data:/app/data
      - ./cache:/app/cache
    ports:
      - "8001:8001"

  streamlit:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    volumes:
      - ./frontend:/app/frontend
    ports:
      - "8501:8501"
    depends_on:
      - api

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

#  searxng:
#    image: searxng/searxng:latest
#    volumes:
#      - ./searxng:/etc/searxng
#    ports:
#      - "8888:8080"

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage

  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
    depends_on:
      - api
      - streamlit

volumes:
  redis_data:
  qdrant_data:
