FROM python:3.11-bullseye

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    cmake \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Create app directory
WORKDIR /app

# Install llama-cpp-python
RUN pip install --no-cache-dir llama-cpp-python[server]

# Create models directory
RUN mkdir -p /models

# Expose port
EXPOSE 8000

# Run server
CMD ["python", "-m", "llama_cpp.server", \
     "--model", "/models/Magistral-Small-2506-Q4_0.gguf", \
     "--chat_format", "mistral-instruct", \
     "--n_ctx", "40960", \
     "--host", "0.0.0.0", \
     "--port", "8000", \
     "--n_threads", "4", \
     "--n_batch", "512"]
